{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78314af4",
   "metadata": {},
   "source": [
    "# install the ollama in local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1840b013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.3.6-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting ollama<1.0.0,>=0.5.1 (from langchain-ollama)\n",
      "  Downloading ollama-0.5.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langchain-ollama) (0.3.74)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.4.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from ollama<1.0.0,>=0.5.1->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.32.4)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/langchain_experiments/lib/python3.11/site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (1.3.0)\n",
      "Downloading langchain_ollama-0.3.6-py3-none-any.whl (24 kB)\n",
      "Downloading ollama-0.5.3-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama, langchain-ollama\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [langchain-ollama]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-ollama-0.3.6 ollama-0.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e36ff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down why LangChain is so great for working with Large Language Models (LLMs). It’s become incredibly popular and powerful, and here’s a breakdown of what makes it stand out:\n",
      "\n",
      "**1. Framework for Building LLM Applications – It’s Not Just a Tool, It’s a System:**\n",
      "\n",
      "* **Abstraction & Modularization:** LangChain isn’t just about using an LLM; it’s about *building* applications around them. It provides a structured framework that breaks down complex tasks into manageable, reusable components. This is a HUGE advantage.\n",
      "* **Components & Tools:** It offers a collection of pre-built components that simplify common tasks:\n",
      "    * **Models:** Easy access to various LLMs (GPT-3, Llama 2, Claude, etc.) through a consistent interface.\n",
      "    * **Prompts:** Tools for crafting effective prompts – this is *critical* for getting good results from LLMs. LangChain has sophisticated prompt management.\n",
      "    * **Chains:**  These are sequences of calls to LLMs or other tools.  You can chain together multiple steps to create complex workflows.  Think of it as building a pipeline.\n",
      "    * **Memory:**  Allows LLMs to remember previous interactions in a conversation or context. This is vital for chatbots and more interactive applications.\n",
      "    * **Agents:**  This is a really exciting part. Agents use LLMs to *decide* what actions to take – like searching the web, calling another API, or performing a calculation. This dramatically increases flexibility.\n",
      "    * **Document Loaders:**  Easily load data from various sources (PDFs, websites, databases) into the LLM.\n",
      "    * **Vectorstores:**  Store and retrieve information efficiently, allowing for semantic search and retrieval.\n",
      "\n",
      "\n",
      "**2. Key Advantages & Benefits:**\n",
      "\n",
      "* **Rapid Prototyping:**  LangChain makes it incredibly easy to build and test LLM applications quickly. You don’t need to write everything from scratch.\n",
      "* **Modularity & Reusability:** Components are designed to be reused across different projects and applications.\n",
      "* **Community & Ecosystem:**  A large and active community means you'll find plenty of examples, tutorials, and support.\n",
      "* **Focus on Chains & Agents:** The emphasis on chains and agents is a key differentiator. It’s designed to handle more complex, dynamic workflows.\n",
      "* **Supports Multiple LLMs:**  It’s designed to work with a wide variety of LLMs, reducing vendor lock-in.\n",
      "* **Documentation & Examples:** LangChain provides excellent documentation and examples to get you started.\n",
      "\n",
      "\n",
      "**3. Popular Use Cases – What are people building with it?**\n",
      "\n",
      "* **Chatbots:** Building conversational AI assistants.\n",
      "* **Question Answering:** Creating systems that answer questions based on a knowledge base.\n",
      "* **Text Summarization:** Automatically generating summaries of documents.\n",
      "* **Code Generation:**  Using LLMs to write and debug code.\n",
      "* **Data Extraction:**  Pulling specific information from text.\n",
      "* **Agent-Based Applications:**  Creating systems that can autonomously perform tasks.\n",
      "\n",
      "\n",
      "**In short, LangChain is a powerful toolkit that simplifies the process of working with LLMs, making it easier to build sophisticated and practical applications.**\n",
      "\n",
      "**To help me give you even *more* tailored information, could you tell me:**\n",
      "\n",
      "*   **What kind of LLM are you planning to use?** (e.g., GPT-4, Llama 2, Claude)\n",
      "*   **What are you hoping to *do* with the LLM?** (e.g., build a chatbot, answer questions, generate creative text?)\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "chat = ChatOllama(\n",
    "    model=\"gemma3:1b\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant.\",\n",
    "    ),\n",
    "    (\"human\", \"What makes LangChain great for working with LLMs?\"),\n",
    "]\n",
    "ai_msg = chat.invoke(messages)\n",
    "print(ai_msg.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
